---
content_type: page
description: This section provides discussion topics and related readings for the
  course.
learning_resource_types: []
ocw_type: CourseSection
title: Discussion
uid: c18a0843-3319-98dc-7d4e-ce0494a435c0
---

Nonnegative Matrix Factorization
--------------------------------

Discussion: When does well-posedness lead to better algorithms?

Balcan, M., A. Blum, et al. {{% resource_link "b429f9a7-c650-48f2-b849-b5c35df6babf" "\"Clustering under Approximation Stability.\" (PDF)" %}} _Journal of the ACM_ (2013).

Tensor Decompositions
---------------------

Discussion: When do algorithms rely (too much) on a distributional model?

Feige, U., and J. Kilian. "{{% resource_link "c7397671-3cef-4469-8431-045b7a2e0aa8" "Heuristics for Semirandom Graph Problems" %}}." _Journal of Computing and System Sciences_ 63, no. 4 (2001): 639–71.

Sparse Coding
-------------

Discussion: When does belief propagation (provably) work?

Geman, S., and D. Geman. "{{% resource_link "7451d1e5-954d-4a4e-b1d5-6a119fcbbf81" "Stochastic Relaxation, Gibbs Distributions, and the Bayesian Restoration of Images" %}}." _Pattern Analysis and Machine Intelligence_ (1984).

Learning Mixture Models
-----------------------

Discussion: Is nature an adversary? And if not, how can we model and exploit that?

Bhaskara, A., M. Charikar, et al. "{{% resource_link "04928e9a-68c0-45d9-844a-ede7016ca9e0" "Smoothed Analysis of Tensor Decompositions" %}}." _Symposium on Theory of Computing_ (2014).

Linear Inverse Problems
-----------------------

Discussion: Do we have enough average-case assumptions?

Berthet, Q., and P. Rigollet. "{{% resource_link "5fdc2a26-b320-4dd5-b115-043033f76f7b" "Computational Lower Bounds for Sparse PCA" %}}." _Conference on Learning Theory_ (2013).

Chandrasekaran, V., and M. Jordan. "{{% resource_link "a7d70613-48b9-438b-a27f-5b902d410675" "Computational and Statistical Tradeoffs via Convex Relaxation" %}}." _Proceedings of the National Academy of Sciences of the United States of America_ 110, no. 13 (2013): E1181–90.